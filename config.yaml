## Path related configurations:
chromedriver_path: ''
chromium_path: ''
log_file_path: 'Logs/___.txt'
dataset_input_path: 'Datasets/___.csv'
dataset_output_path: 'Datasets/___.csv'

## few-shot examples related configurations (STANDARD PROMPTING):
kshot_examples_path: "Prompts/standard_kshot.txt"
italian_kshot_examples_path: "Prompts/standard_kshot_it.txt"
spanish_kshot_examples_path: "Prompts/standard_kshot_es.txt"

## Column names:
label_column_name: 'converted_label' #'reviewRating.alternateName'
claim_column_name: 'claimReviewed'
author_column_name: 'itemReviewed.author.name'
date_column_name: 'itemReviewed.datePublished'
prediction_column_name: 'predicted_label_<std/hiss/react>_<8B/70B>'
domain_column_name: 'domain'

## Search related configurations:
max_results: 5
max_sentences: 3
max_searches: 3
max_scraped_sentences: 250 #limit the number of sentences scraped from the web page for performance reasons
max_sentence_length: 1000

## Window related configurations:
windowed: False
window_size: 5

## Weight on token overlap related to the relevance score of the sentences
overlap_rate: 0

## Model related configurations:
language: "en"
#model_name: "Llama 3.1 8B"
model_name: "Llama 3.1 70B"
#model_name: "Llama 3.1 405B"
#model_name: "Gemma 2 9B"
#model_id: "meta-llama/Meta-Llama-3.1-8B-Instruct"
model_id: "meta-llama/Meta-Llama-3.1-70B-Instruct"
#model_id: "meta-llama/Meta-Llama-3.1-405B-Instruct"
#model_id: "google/gemma-2-9b-it"
temperature: 0
max_tokens: 1000
already_predicted_claims: 0

possible_labels: ['mostly false', 'mostly-false', 'mostly true', 'mostly-true', 'false', 'mixture', 'true']

## Blacklists:
url_blacklist: ['facebook.com', 'google.com', 'youtube.com','politifact.com','quora.com','reddit.com']
tag_blacklist: ['header', 'footer', 'nav', 'aside', 'script', 'style', 'meta', 'head', 'h1', 'h2', 'h3']
type_blacklist: [".pdf"]

## System prompts:
#standard_system_prompt_1: >
#  You are a fact-checking expert. Evaluate the truthfulness of a statement given by the user.
#  Use the given function to make a google search, and give it as parameter the query that you think will help you find relevant information.
#  The query should not include the date of the statement.

standard_system_prompt_1: >
  You are a fact-checking expert. Evaluate the truthfulness of a statement given by the user.
  Always reply either in the format 'Query: {query}' and terminate generation to tell the user to perform a google search with the query of your choice,
  or you can reply in the format '{reasoning} Final answer: {verdict}'.

italian_system_prompt_1: >
  Sei un esperto di fact-checking. Valuta la veridicità di un claim dato dall'utente.
  Rispondi sempre nel formato 'Query: {query}' e termina la generazione per dire all'utente di fare una ricerca su google con la query da te scelta,
  oppure rispondere nel formato 'Ragionamento: {ragionamento} Verdetto finale: {verdetto}'.

spanish_system_prompt_1: >
  Eres un experto en verificación de hechos. Evalúa la veracidad de un claim dado por el usuario.
  Responde siempre en el formato 'Query: {query}' y termina la generación para decir al usuario que realice una búsqueda en Google con la consulta que elegiste,
  o responde en el formato 'Razonamiento: {razonamiento} Veredicto final: {veredicto}'.

#standard_system_prompt_2: >
#  Consider your sources, context and date while assessing. to answer return 'Final answer: {verdict}, {reason}.'
#  You must respond with a valid verdict ('false','mostly-false','half-true','mostly-true','true') or 'uncertain',
#  providing reasoning and citing sources by providing the domain of the pertinent search results.
#  If you decide to use the function, respond in the format {"name": "google_search", "parameters": {"query": query of your choice}} and terminate.
#  The function will be executed by the system and you will receive the output to use in your response.
#  Do not use variables. 

standard_system_prompt_2: >
  Consider your sources, context and date while assessing.
  You must respond with a valid verdict ('false','mostly-false','mixture','mostly-true','true'),
  providing reasoning and citing sources by providing the domain of the pertinent search results.

italian_system_prompt_2: >
  Considera le tue fonti, il contesto e la data mentre valuti.
  Devi rispondere con un verdetto valido ['false','mostly-false','mixture','mostly-true','true'],
  fornendo ragionamento e citando le fonti fornendo il dominio dei risultati di ricerca pertinenti.

spanish_system_prompt_2: >
  Considera tus fuentes, el contexto y la fecha mientras evalúas.
  Debes responder con un veredicto válido ['false', 'mostly-false', 'mixture', 'mostly-true', 'true'],
  proporcionando razonamiento y citando las fuentes, incluyendo el dominio de los resultados de búsqueda pertinentes.

## Tools:
tools: [{
        "type": "function",
        "function": {
            "name": "google_search",
            "description": "Get the google search results given a query",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "the query that will be used to perform the search. Do not include the given date as part of the query"
                    }
                },
                "required": [
                    "query"
                ]
            },
            "return": {
                "type": "string",
                "description": "A sting containing the list of website given by the search results along with a snippet of their content."
            }
        }
      }]

#tools: [{
#        "type": "function",
#        "function": {
#            "name": "get_current_temperature",
#            "description": "Get the current temperature at a location.",
#            "parameters": {
#                "type": "object",
#                "properties": {
#                    "location": {
#                        "type": "string",
#                        "description": "The location to get the temperature for, in the format 'City, Country'"
#                    }
#                },
#                "required": [
#                    "location"
#                ]
#            },
#            "return": {
#                "type": "string",
#                "description": "The current temperature at the specified location in the specified units, as a float."
#            }
#        }
#      }]
