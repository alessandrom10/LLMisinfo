chromedriver_path: 'C:\\Users\\flash\\Documents\\UNI\\MAG-ANNOII\\MDP\\chromedriver-win64\\chromedriver.exe'
dataset_path: 'C:\\Users\\flash\\Documents\\UNI\\MAG-ANNOII\\MDP\\dataset'
chromium_path: 'C:\\Users\\flash\\AppData\\Local\\Chromium\\Application\\chrome.exe'

#chromedriver_path: 'C:\\Users\\migue\\OneDrive - UNIVERSIDAD DE SEVILLA\\Escritorio\\Universidad\\Master Polimi\\MDP\\LLMisinfo-MDP\\chromium\\chromedriver.exe'
#dataset_path: 'C:\\Users\\flash\\Documents\\UNI\\MAG-ANNOII\\MDP\\dataset'
#chromium_path: 'C:\\Users\\migue\\OneDrive - UNIVERSIDAD DE SEVILLA\\Escritorio\\Universidad\\Master Polimi\\MDP\\LLMisinfo-MDP\\chromium\\chrome-win\\chrome.exe'

#max number of results
max_results: 5
max_sentences: 3
max_searches: 3
windowed: False
window_size: 5

language: "en"
#model_name: "Llama 3.1 8B"
model_name: "Llama 3.1 70B"
#model_name: "Llama 3.1 405B"
#model_name: "Gemma 2 9B"
#model_id: "meta-llama/Meta-Llama-3.1-8B-Instruct"
model_id: "meta-llama/Meta-Llama-3.1-70B-Instruct"
#model_id: "meta-llama/Meta-Llama-3.1-405B-Instruct"
#model_id: "google/gemma-2-9b-it"

temperature: 0
max_tokens: 1000

url_blacklist: ['facebook.com', 'google.com', 'youtube.com','politifact.com','quora.com','reddit.com']
tag_blacklist: ['header', 'footer', 'nav', 'aside', 'script', 'style', 'meta', 'head', 'h1', 'h2', 'h3']
type_blacklist: [".pdf"]

#standard_system_prompt_1: >
#  You are a fact-checking expert. Evaluate the truthfulness of a statement given by the user.
#  Use the given function to make a google search, and give it as parameter the query that you think will help you find relevant information.
#  The query should not include the date of the statement.

standard_system_prompt_1: >
  You are a fact-checking expert. Evaluate the truthfulness of a statement given by the user.
  Always reply either in the format 'Query: {query}' and terminate generation to tell the user to perform a google search with the query of your choice,
  or you can reply in the format '{reasoning} Final answer: {verdict}'.

#standard_system_prompt_2: >
#  Consider your sources, context and date while assessing. to answer return 'Final answer: {verdict}, {reason}.'
#  You must respond with a valid verdict ('false','mostly-false','half-true','mostly-true','true') or 'uncertain',
#  providing reasoning and citing sources by providing the domain of the pertinent search results.
#  If you decide to use the function, respond in the format {"name": "google_search", "parameters": {"query": query of your choice}} and terminate.
#  The function will be executed by the system and you will receive the output to use in your response.
#  Do not use variables. 

standard_system_prompt_2: >
  Consider your sources, context and date while assessing.
  You must respond with a valid verdict ('false','mostly-false','mixture','mostly-true','true'),
  providing reasoning and citing sources by providing the domain of the pertinent search results.
# or 'uncertain'  
#The function will be executed by the system and you will receive the output to use in your response.
#Do not use variables. 

kshot_examples_path: "Prompts/standard_kshot.txt"

tools: [{
        "type": "function",
        "function": {
            "name": "google_search",
            "description": "Get the google search results given a query",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "the query that will be used to perform the search. Do not include the given date as part of the query"
                    }
                },
                "required": [
                    "query"
                ]
            },
            "return": {
                "type": "string",
                "description": "A sting containing the list of website given by the search results along with a snippet of their content."
            }
        }
      }]

#tools: [{
#        "type": "function",
#        "function": {
#            "name": "get_current_temperature",
#            "description": "Get the current temperature at a location.",
#            "parameters": {
#                "type": "object",
#                "properties": {
#                    "location": {
#                        "type": "string",
#                        "description": "The location to get the temperature for, in the format 'City, Country'"
#                    }
#                },
#                "required": [
#                    "location"
#                ]
#            },
#            "return": {
#                "type": "string",
#                "description": "The current temperature at the specified location in the specified units, as a float."
#            }
#        }
#      }]

hiss_messages: [
    {role: "system", content: "You are a fact-checking expert. reply with the next step in the fact verification process following the provided examples."},
    # example 1
    {role: "user", content: "Claim: \"Emerson Moser, who was Crayola's top crayon molder for almost 40 years, was colorblind.\""},
    {role: "assistant", content: "A fact checker will decompose the claim into 4 subclaims that are easier to verify:\n1. Emerson Moser was a crayon molder at Crayola.\n2. Moser worked at Crayola for almost 40 years.\n3. Moser was Crayola’s top crayon molder.\n4. Moser was colorblind.\nTo verify subclaim 1, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Is there any official record or documentation indicating that Emerson Moser worked as a crayon molder at Crayola?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "Yes.\nAnswer: Yes.\nTo verify subclaim 2, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Are there any official records or documentation confirming Emerson Moser’s length of employment at Crayola"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: Emerson Moser, who is retiring next week after 35 years, isn't colorblind in the sense that he can't see color at all. It's just that some .."},
    {role: "assistant", content: "To verify subclaim 3, a fact-checker will go through a step-by-step process to ask and answer a series of questions elevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Are there credible sources or publications that mention Emerson Moser as Crayola's top crayon molder?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "Yes.\nAnswer: Yes.\nTo verify subclaim 4, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Are there any credible sources or records indicating that Emerson Moser was colorblind?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "Yes. Question: Was Emerson Moser's colorblindness only confusing for certain colors?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: Moser has had tritanomaly, a type of colorblindness that makes it difficult to distinguish between blue and green and between yellow and red."},
    {role: "assistant", content: "Based on the answers to these questions, it is clear that among pants-fire, false, barely-true, half-true, mostly-true, and true, the claim can be classified as mostly-true."},
    # example 2
    {role: "user", content: "Claim: \"Bernie Sanders said 85 million Americans have no health insurance.\""},
    {role: "assistant", content: "A fact checker will not split the claim since the original claim is easier to verify.\nTo verify the claim, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: How many Americans did Bernie Sanders claim had no health insurance?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: \"We have 85 million Americans who have no health insurance,\" Sanders said Dec. 11 on CNN's State of the Union."},
    {role: "assistant", content: "Question: How did Bernie Sanders define 'no health insurance'?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: Sanders spokesperson Mike Casca said the senator was referring to the number of uninsured and under-insured Americans and cited a report about those numbers for adults."},
    {role: "assistant", content: "Question: How many Americans were uninsured or under-insured according to the Commonwealth Fund survey?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: The Commonwealth Fund survey found that 43% of working-age adults 19 to 64, or about 85 million Americans, were uninsured or inadequately insured."},
    {role: "assistant", content: "Question: Is the statement 'we have 85 million Americans who have no health insurance' partially accurate according to the information in the passage?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: Bernie Sanders omitted that his figure included people who either have no health insurance or are under-insured."},
    {role: "assistant", content: "Based on the answers to these questions, it is clear that among pants-fire, false, barely-true, half-true, mostly-true, and true, the claim is classified as half-true."},
    # example 3
    {role: "user", content: "Claim: \"JAG charges Nancy Pelosi with treason and seditious conspiracy.\""},
    {role: "assistant", content: "A fact checker will decompose the claim into 2 subclaims that are easier to verify:\n1. JAG has made a claim or accusation against Nancy Pelosi.\n2. The specific charges or allegations made against Nancy Pelosi are treason and seditious conspiracy.\nTo verify subclaim 1, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Is it true that JAG has made a claim or accusation against Nancy Pelosi?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: There is no evidence to support this claim and a spokesperson for the U.S. Navy Judge Advocate General's Corps has stated that it is not true."},
    {role: "assistant", content: "To verify subclaim 2, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Is it true that the specific charges or allegations made against Nancy Pelosi are treason and seditious conspiracy?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: There is no evidence to support this claim."},
    {role: "assistant", content: "Question: Where is the source of the claim?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: Real Raw News, a disclaimer stating that it contains 'humor, parody and satire' and has a history of publishing fictitious stories."},
    {role: "assistant", content: "Based on the answers to these questions, it is clear that among pants-fire, false, barely-true, half-true, mostly-true, and true, the claim is classified as pants-fire."},
    # example 4
    {role: "user", content: "Claim: \"Cheri Beasley 'backs tax hikes— even on families making under $75,000.'\""},
    {role: "assistant", content: "A fact checker will decompose the claim into 2 subclaims that are easier to verify:\n1. Cheri Beasley supports tax increases.\n2. Cheri Beasley supports tax increases for families with an income under $75,000.\nTo verify subclaim 1, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Does Cheri Beasley supports tax increases?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "Yes.\n Answer: Beasley supports student loan bailouts for the wealthy.\nTo verify subclaim 2, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Does the ad accurately link Beasley's position on student loan debt forgiveness with her stance on tax hikes for families making under $75,000 per year?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: The ad makes a misleading connection between the two issues and does not accurately represent Beasley's position on tax hikes for families making under $75,000 per year."},
    {role: "assistant", content: "Based on the answers to these questions, it is clear that among pants-fire, false, barely-true, half-true, mostly-true, and true, the claim is classified as barely-true."}
]

test_hiss_prompt: [
    {role: "user", content: "Claim: \"Donald Trump has said he loves war, 'including with nukes.'s\""},
    {role: "assistant", content: "A fact checker will decompose the claim into 2 subclaims that are easier to verify:\n1. Donald Trump has expressed a love for war.\n2. Donald Trump has expressed a love for nuclear wars.\nTo verify subclaim 1, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Has Donald Trump expressed a love for war?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: [...] Donald Trump said \"I'm really good at war. I love war in a certain way. But only when we win.\" [...]"},
    {role: "assistant", content: "Question: In what context did Donald Trump express a love for war?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer: [...] after he said that former Iraqi President Saddam Hussein claimed to have weapons of mass destruction as a strategy \"to scare\" Iran. [...]"},
    {role: "assistant", content: "To verify subclaim 2, a fact-checker will go through a step-by-step process to ask and answer a series of questions relevant to its factuality. Here are the specific steps he/she raise each question and look for an answer:\nQuestion: Has Donald Trump expressed a love for war including nukes?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "Yes.\nAnswer: No. The voices talking up dangers of nuclear war include Trump.\nQuestion: What was the context Trump express 'including nukes'?"},
    {role: "user", content: "Tell me if you are confident to answer the question or not. Answer with 'yes' or 'no':"},
    {role: "assistant", content: "No."},
    {role: "user", content: "Answer:[...] Trump suggested that Japan might need to acquire nuclear weapons to defend against neighboring North Korea [...]"},
    {role: "assistant", content: "Based on the answers to these questions, it is clear that among pants-fire, false, barely-true, half-true, mostly-true, and true, the claim is classified as half-true."},
]